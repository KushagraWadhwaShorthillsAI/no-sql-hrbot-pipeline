import os
import json
import argparse
import asyncio
import httpx
from pymongo import MongoClient
from .config import MONGO_URI, DB_NAME, COLLECTION_NAME
from dotenv import load_dotenv
from .search_builder import bm25_pipeline
from collections import defaultdict

load_dotenv()
PIPELINE_MODE = os.getenv("PIPELINE_MODE", "false").lower() == "true"
LOG_FILE = "logs/nosql_pipeline.log" if PIPELINE_MODE else "logs/nosql_retriever.log"

def log(msg):
    with open(LOG_FILE, "a", encoding="utf-8") as f:
        f.write(msg + "\n")

def safe_json_load(text: str):
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        print("âŒ Failed to parse JSON from LLM response.")
        return None

def apply_rrf(bm25_hits, vector_hits, k_rrf=60):
    """
    Applies Reciprocal Rank Fusion over two ranked lists (BM25 + Vector).
    Returns a unified list of resumes sorted by fused RRF score.
    """
    rank_scores = {}

    def score_doc(doc, rank, weight=1.0):
        _id = str(doc.get("_id", doc.get("email", doc.get("name", ""))))
        rank_scores.setdefault(_id, {
            "doc": doc,
            "rrf_score": 0,
            "sources": [],
        })
        rank_scores[_id]["rrf_score"] += weight / (k_rrf + rank)
        rank_scores[_id]["sources"].append(rank)

    for rank, doc in enumerate(bm25_hits):
        score_doc(doc, rank, weight=1.0)

    for rank, doc in enumerate(vector_hits):
        score_doc(doc, rank, weight=1.0)

    fused = list(rank_scores.values())
    fused.sort(key=lambda x: x["rrf_score"], reverse=True)

    return [
        {**entry["doc"], "rrf_score": entry["rrf_score"]}
        for entry in fused
    ]



class ResumeRetriever:
    def __init__(self):
        self.azure_key = os.getenv("AZURE_OPENAI_API_KEY")
        self.azure_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
        self.azure_deployment = os.getenv("AZURE_OPENAI_DEPLOYMENT")
        self.azure_version = os.getenv("AZURE_OPENAI_API_VERSION", "2024-08-01-preview")

        self.gemini_key = os.getenv("GEMINI_API_KEY")
        self.gemini_model = os.getenv("GEMINI_MODEL", "gemini-2.0-flash")

        self.collection = MongoClient(MONGO_URI)[DB_NAME][COLLECTION_NAME]

    async def call_azure_llm(self, prompt: str) -> str:
        headers = {
            "Content-Type": "application/json",
            "api-key": self.azure_key,
        }
        body = {
            "messages": [
                {"role": "system", "content": "You are a helpful assistant that extracts keywords from natural language queries for robust MongoDB document search."},
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.2,
            "max_tokens": 6000,
        }
        url = f"{self.azure_endpoint}/openai/deployments/{self.azure_deployment}/chat/completions?api-version={self.azure_version}"

        async with httpx.AsyncClient(timeout=60) as client:
            print("ğŸŒ Sending request to Azure...")
            response = await client.post(url, headers=headers, json=body)
            response.raise_for_status()
            return response.json()["choices"][0]["message"]["content"]

    async def call_gemini_llm(self, prompt: str) -> str:
        if not self.gemini_key:
            raise ValueError("âŒ GEMINI_API_KEY not set in .env")

        url = f"https://generativelanguage.googleapis.com/v1beta/models/{self.gemini_model}:generateContent?key={self.gemini_key}"
        payload = {"contents": [{"parts": [{"text": prompt}]}]}
        headers = {"Content-Type": "application/json"}

        async with httpx.AsyncClient(timeout=60) as client:
            print("ğŸŒ Sending request to Gemini...")
            response = await client.post(url, headers=headers, json=payload)
            response.raise_for_status()
            return response.json()["candidates"][0]["content"]["parts"][0]["text"]

    def clean_llm_response(self, text: str) -> str:
        cleaned = text.strip()
        if cleaned.startswith("```json") and cleaned.endswith("```"):
            return cleaned[7:-3].strip()
        elif cleaned.startswith("```") and cleaned.endswith("```"):
            return cleaned[3:-3].strip()
        return cleaned

    async def extract_keywords(self, query: str, use_gemini=False) -> list[str]:
        print("\nğŸ§  Extracting enriched keywords...")

        prompt = f"""
You are an intelligent keyword extraction and enrichment engine for a resume retrieval system using MongoDB.

Your job is to extract the most relevant keywords or phrases from a natural language HR query. These keywords will be used to build $regex-based MongoDB queries to find matching resumes from a structured NoSQL database.

--- Context ---
Each resume is a JSON object with fields like:
- name, summary, skills, experience (title, company, description), education, certifications, projects, etc.

--- Your Objective ---
From the query, extract:
âœ“ Core technical and non-technical keywords
âœ“ Job titles, skills, tools, responsibilities, locations (e.g., "team lead", "api testing", "onboarding process")
âœ“ Phrases describing HR actions or managerial work (e.g., "managed payroll", "conducted training")
âœ“ Domain-specific or industry terms (e.g., "e-commerce", "finance")
âœ“ Degrees, certifications (e.g., "MBA", "PMP certified")
âœ“ Named candidates (e.g., "rahul sharma") along with other relevant keywords
âœ“ If the query is explicitly asking about info of some particular candidate only give keywords of their names.

--- Enrichment Rules ---
âœ“ For each keyword/phrase, also include:
  - Related terms that people usually put in their resumes instead of the exact keywords extracted (e.g., "REST" â†’ "rest api", "restful api")
  - Decomposed tokens for multi-word phrases (e.g., "rahul sharma" â†’ "rahul", "sharma")
âœ“ Maintain all original keywords too.
âœ“ try to break the keywords into meanigful singular words as well that can help in better keyword search.

--- What to Avoid ---
âœ— Don't include standalone generic verbs like "implemented", "built", "worked" in case of technical skills related query if required you can keep them for non tech queries
âœ“ Only keep such verbs if part of a meaningful phrase like "implemented payroll system"
âœ— Don't include vague or overfit terms like "tools", "project", "experience", unless explicitly needed

--- Output Format ---
Return only a **valid JSON array** of strings. Example:
["api testing", "rest api", "payroll", "rahul sharma", "rahul"]

--- Query ---
{query}
"""

        try:
            raw = await (self.call_gemini_llm(prompt) if use_gemini else self.call_azure_llm(prompt))
            print("ğŸ“ Raw LLM Response:", raw)
            cleaned = self.clean_llm_response(raw)
            print("âœ… Cleaned Response:", cleaned)
            keywords = json.loads(cleaned) if cleaned.startswith("[") else []
            if not isinstance(keywords, list):
                print("âš ï¸ Keyword list is not a valid JSON array.")
                return []
            keywords = list(set(k.strip().lower() for k in keywords if isinstance(k, str) and k.strip()))
            log("ğŸ¯ Final Keywords: " + json.dumps(keywords, indent=2))
            return keywords
        except Exception as e:
            print(f"âŒ Keyword extraction failed: {e}")
            return []



    def build_mongo_query(self, keywords: list[str]) -> dict:
        print("\nğŸ”§ Building MongoDB OR query...")
        or_conditions = []
        fields = [
            "name","summary", "skills", "projects.description", "projects.title",
            "experience.description", "experience.title", "experience.company",
            "education.institution", "certifications.title", "certifications.issuer",
        ]

        for kw in keywords:
            for field in fields:
                or_conditions.append({field: {"$regex": kw, "$options": "i"}})

        query = {"$or": or_conditions} if or_conditions else {}
        # print("ğŸ“„ Final Mongo Query:\n", json.dumps(query, indent=2))
        return query

    async def search(self, query: str, use_gemini: bool = False) -> dict:
        print(f"\nğŸ” Original NL Query: \"{query}\"")
        keywords = await self.extract_keywords(query, use_gemini)
        if not keywords:
            return {
                "query": query,
                "keywords": [],
                "matched": [],
                "error": "Keyword extraction failed"
            }

        # mongo_query = self.build_mongo_query(keywords)
        # print("\nğŸ” Searching in MongoDB...")
        # results = list(self.collection.find(mongo_query))
        pipeline = bm25_pipeline(keywords, k=300)
        print("\nğŸ” Searching in MongoDB with BM25 pipeline...")
        results  = list(self.collection.aggregate(pipeline))
        
        print(f"\nğŸ“Š Found {len(results)} matching resumes:\n")
        for res in results:
            print(f" - {res.get('name')} | {res.get('email')}")

        return {
            "query": query,
            "keywords": keywords,
            "matched": [
               {**res, "_id": str(res["_id"])} for res in results
            ]
        }
    def log_query_result(self, query: str, keywords: list[str], matched: list[dict], log_path: str):
        log_data = {
            "query": query,
            "keywords": keywords,
            "matched_names": [res.get("name", "Not Provided") for res in matched],
        }
        with open(log_path, "a", encoding="utf-8") as f:
            f.write(json.dumps(log_data, ensure_ascii=False) + "\n")
    
    
    async def embed_query(self, query: str) -> list[float]:
        """
        Embed the query using Azure OpenAI embedding API.
        """
        url = f"{self.azure_endpoint}/openai/deployments/{os.getenv('AZURE_EMBEDDING_DEPLOYMENT')}/embeddings?api-version={os.getenv('AZURE_EMBEDDING_API_VERSION')}"
        headers = {"Content-Type": "application/json", "api-key": self.azure_key}
        body = {"input": query}
        async with httpx.AsyncClient(timeout=60) as client:
            r = await client.post(url, headers=headers, json=body)
            r.raise_for_status()
            return r.json()["data"][0]["embedding"]

    async def vector_search(self, query: str, k: int = 100) -> list[dict]:
        """
        Runs per-field knnBeta vector search and fuses results (via max score).
        """
        print(f"\nğŸ§  Embedding query for vector search: '{query}'")
        qvec = await self.embed_query(query)

        fields = [
            "summary_embed",
            "skills_embed",
            "projects_embed",
            "experience_embed",
            "certifications_embed",
            "education_embed"
        ]

        results_by_id = defaultdict(lambda: {"score_vec": 0.0, "sources": set()})

        for field in fields:
            print(f"ğŸ” Searching field: {field}")
            pipeline = [
                {
                    "$search": {
                        "index": "default_vector",
                        "knnBeta": {
                            "vector": qvec,
                            "path": field,
                            "k": k
                        }
                    }
                },
                { "$project": {
                    "_id": 1,
                    "name": 1,
                    "email": 1,
                    "summary": 1,
                    "score_vec": { "$meta": "searchScore" }
                }}
            ]

            for doc in self.collection.aggregate(pipeline):
                _id = str(doc["_id"])
                if doc["score_vec"] > results_by_id[_id]["score_vec"]:
                    results_by_id[_id].update({
                        "doc": doc,
                        "score_vec": doc["score_vec"],
                    })
                results_by_id[_id]["sources"].add(field)

        print(f"âœ… Fused results from {len(fields)} fields. Found {len(results_by_id)} unique resumes.")

        # Convert and sort
        fused_results = [
            {**v["doc"], "score_vec": v["score_vec"], "matched_fields": list(v["sources"])}
            for v in results_by_id.values()
        ]
        fused_results.sort(key=lambda r: r["score_vec"], reverse=True)

        return fused_results
    
    async def hybrid_search(self, query: str, top_n_each=200) -> dict:
        print(f"\nğŸ¤ Running hybrid search for: '{query}'")

        # Step 1: BM25 (via proper $search pipeline)
        keywords = await self.extract_keywords(query)
        pipeline = bm25_pipeline(keywords, k=top_n_each)
        print("\nğŸ” Searching in MongoDB with BM25 pipeline...")
        bm25_results = list(self.collection.aggregate(pipeline))
        print(f"ğŸ“š BM25 retrieved {len(bm25_results)} resumes")

        # Step 2: Vector
        vector_results = await self.vector_search(query, k=top_n_each)
        print(f"ğŸ§  Vector search returned {len(vector_results)} resumes")

        # Step 3: RRF Fusion
        final = apply_rrf(bm25_results, vector_results)
        print(f"âœ… RRF fusion produced {len(final)} unified results")

        return {
            "query": query,
            "bm25": bm25_results,
            "vector": vector_results,
            "fused": final
        }



if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--query", required=True, help="Natural language resume query")
    parser.add_argument("--use-gemini", action="store_true", help="Use Gemini instead of Azure")
    parser.add_argument("--mode", choices=["bm25", "vector", "hybrid"], default="bm25", help="Retrieval mode (bm25 | vector | hybrid)")
    args = parser.parse_args()

    retriever = ResumeRetriever()

    if args.mode == "bm25":
        result = asyncio.run(retriever.search(args.query, use_gemini=args.use_gemini))
        log_path = "data/nosql_retrieval_logs.jsonl"
        retriever.log_query_result(
            query=result["query"],
            keywords=result["keywords"],
            matched=result["matched"],
            log_path=log_path
        )
    elif args.mode == "hybrid":
        result = asyncio.run(retriever.hybrid_search(args.query))
        
        print("\nğŸ” Top 10 from BM25:")
        for doc in result["bm25"][:10]:
            print(f" - {doc.get('name')} | via BM25")

        print("\nğŸ” Top 10 from Vector:")
        for doc in result["vector"][:10]:
            print(f" - {doc.get('name')} | via Vector")

        print("\nğŸ” Top 10 from RRF Fusion:")
        for doc in result["fused"][:10]:
            print(f" - {doc.get('name')} | RRF score = {doc.get('rrf_score'):.4f}")

    else:
        results = asyncio.run(retriever.vector_search(args.query))
        for r in results[:10]:
            print(f" - {r['name']} | vec_score = {r['score_vec']:.4f} | fields = {', '.join(r['matched_fields'])}")

